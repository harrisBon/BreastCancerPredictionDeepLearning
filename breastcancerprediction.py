# -*- coding: utf-8 -*-
"""BreastCancerPrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w4llMjL9pJvZGe8wELKOjGIXJ0IPlwYA
"""

# Commented out IPython magic to ensure Python compatibility.
#import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader,TensorDataset
from sklearn.model_selection import train_test_split
from IPython import display
display.set_matplotlib_formats('svg')
# %matplotlib inline

from google.colab import files
uploaded=files.upload()

import io
df=pd.read_csv(io.BytesIO(uploaded["breast-cancer.csv"]))

df.head(10)

df.info()

df.describe()

df.groupby('diagnosis').describe()

df['diagnosis'].value_counts()

df.isnull().sum()

plt.figure(figsize=(40,7))
sns.boxplot(data=df.drop(['diagnosis','id'], axis=1))
plt.tight_layout()
plt.show()

df.corr()

df=df.drop('id',axis=1)

df.head()

plt.figure(figsize=(20,7))
sns.heatmap(df.corr(),annot=True,cmap='viridis')
plt.show()

diag_dummies=pd.get_dummies(df['diagnosis'],drop_first=True)
df=pd.concat([df.drop('diagnosis',axis=1),diag_dummies],axis=1)
df.columns

df.head()

import scipy.stats as stats
clmnszscore=df.keys()
clmnszscore=clmnszscore.drop('M')
df[clmnszscore]=df[clmnszscore].apply(stats.zscore)
df.head()

dfT=torch.tensor(df[clmnszscore].values).float()
diagT=torch.tensor(df['M'].values).float()
diagT=diagT[:,None]

print(diagT.shape)
print(dfT.shape)

train_data,test_data,train_diag,test_diag=train_test_split(dfT,diagT,test_size=.1)
train_data=TensorDataset(train_data,train_diag)
test_data=TensorDataset(test_data,test_diag)

batchsize=32
trainLoader=DataLoader(train_data,batch_size=batchsize,shuffle=True,drop_last=True)
testLoader=DataLoader(test_data,batch_size=test_data.tensors[0].shape[0])

# create a class for the model 

class theNet(nn.Module):
  def __init__(self):
    super().__init__()

    ### input layer
    self.input = nn.Linear(30,60)
    
    ### hidden layers
    self.fc1    = nn.Linear(60,30)
    
    self.fc2    = nn.Linear(30,30)
    

    ### output layer
    self.output = nn.Linear(30,1)
  
  # forward pass
  def forward(self,x):

    # input (x starts off normalized)
    x = F.relu( self.input(x) )


    
    

    
   # hidden layer 1
    x = F.relu( self.fc1(x) )

   # hidden layer 2
    x = F.relu( self.fc2(x) )

  # output layer
    return self.output(x)

# a function that trains the model

# global parameter
numepochs = 100

def trainTheModel():

  # loss function and optimizer
  lossfun = nn.BCEWithLogitsLoss()
  optimizer = torch.optim.SGD(net.parameters(),lr=.01)

  # initialize losses
  losses   = torch.zeros(numepochs)
  trainAcc = []
  testAcc  = []

  # loop over epochs
  for epochi in range(numepochs):

    # switch on training mode
    net.train()

    # loop over training data batches
    batchAcc  = []
    batchLoss = []
    for X,y in trainLoader:

      # forward pass and loss
      yHat = net(X)
      loss = lossfun(yHat,y)

      # backprop
      optimizer.zero_grad()
      loss.backward()
      optimizer.step()

      # loss from this batch
      batchLoss.append(loss.item())

      # compute training accuracy for this batch
      batchAcc.append( 100*torch.mean(((yHat>0) == y).float()).item() )
    # end of batch loop...

    # now that we've trained through the batches, get their average training accuracy
    trainAcc.append( np.mean(batchAcc) )

    # and get average losses across the batches
    losses[epochi] = np.mean(batchLoss)



    ### test accuracy

   
    net.eval()
    X,y = next(iter(testLoader)) # extract X,y from test dataloader
    with torch.no_grad(): # deactivates autograd
      yHat = net(X)
    testAcc.append( 100*torch.mean(((yHat>0) == y).float()).item() )
  
  # function output
  return trainAcc,testAcc,losses

# create and train a model 
net = theNet()
trainAcc,testAcc,losses = trainTheModel()

# plot the results
fig,ax = plt.subplots(1,3,figsize=(17,5))

ax[0].plot(losses)
ax[0].set_title('Losses')


ax[1].plot(trainAcc)
ax[1].set_title('Train accuracy')


ax[2].plot(testAcc)
ax[2].set_title('Test Accuracy')
print(f'Final Model Test Accuracy:{testAcc[-1]:.2f}')


plt.show()

# predictions for training data
train_predictions = net(trainLoader.dataset.tensors[0])
train_predictions

# predictions for test data
test_predictions = net(testLoader.dataset.tensors[0])
test_predictions

#use scikitlearn to compute ARPF
import sklearn.metrics as skm

# initialize vectors
train_metrics = [0,0,0,0]
test_metrics  = [0,0,0,0]

# training
train_metrics[0] = skm.accuracy_score (trainLoader.dataset.tensors[1],train_predictions>0)
train_metrics[1] = skm.precision_score(trainLoader.dataset.tensors[1],train_predictions>0)
train_metrics[2] = skm.recall_score   (trainLoader.dataset.tensors[1],train_predictions>0)
train_metrics[3] = skm.f1_score       (trainLoader.dataset.tensors[1],train_predictions>0)


# test
test_metrics[0] = skm.accuracy_score (testLoader.dataset.tensors[1],test_predictions>0)
test_metrics[1] = skm.precision_score(testLoader.dataset.tensors[1],test_predictions>0)
test_metrics[2] = skm.recall_score   (testLoader.dataset.tensors[1],test_predictions>0)
test_metrics[3] = skm.f1_score       (testLoader.dataset.tensors[1],test_predictions>0)

plt.bar(np.arange(4)-.1,train_metrics,.5)
plt.bar(np.arange(4)+.1,test_metrics,.5)
plt.xticks([0,1,2,3],['Accuracy','Precision','Recall','F1-score'])
plt.ylim([.6,1])
plt.legend(['Train','Test'])
plt.title('Performance metrics')
plt.show()

# Confusion matrices
trainConfmat = skm.confusion_matrix(trainLoader.dataset.tensors[1],train_predictions>0)
testConfmat  = skm.confusion_matrix(testLoader.dataset.tensors[1], test_predictions>0)

fig,ax = plt.subplots(1,2,figsize=(12,7))

# confmat during TRAIN
ax[0].imshow(trainConfmat,'Blues',vmax=len(train_predictions)/2)
ax[0].set_xticks([0,1])
ax[0].set_yticks([0,1])
ax[0].set_xlabel('Predicted diagnosis')
ax[0].set_ylabel('True diagnosis')
ax[0].set_title('TRAIN confusion matrix')

# add text labels
ax[0].text(1,1,f'True negatives:\n{trainConfmat[0,0]}' ,ha='center',va='center')
ax[0].text(0,1,f'False negatives:\n{trainConfmat[1,0]}',ha='center',va='center')
ax[0].text(0,0,f'True positives:\n{trainConfmat[1,1]}' ,ha='center',va='center')
ax[0].text(1,0,f'False positives:\n{trainConfmat[0,1]}',ha='center',va='center')




# confmat during TEST
ax[1].imshow(testConfmat,'Blues',vmax=len(test_predictions)/2)
ax[1].set_xticks([0,1])
ax[1].set_yticks([0,1])
ax[1].set_xlabel('Predictes diagnosis')
ax[1].set_ylabel('True diagnosis')
ax[1].set_title('TEST confusion matrix')

# add text labels
ax[1].text(1,1,f'True negatives:\n{testConfmat[0,0]}' ,ha='center',va='center')
ax[1].text(0,1,f'False negatives:\n{testConfmat[1,0]}',ha='center',va='center')
ax[1].text(0,0,f'True positives:\n{testConfmat[1,1]}' ,ha='center',va='center')
ax[1].text(1,0,f'False positives:\n{testConfmat[0,1]}',ha='center',va='center')
plt.show()

#trainConfmat